# üöÄ ETL de Procesamiento de Datos de Visitas Web

**Autor:** Rigoberto Rinc√≥n Ballesteros  
**Repositorio:** ETL de Visitas Web  
**Tecnolog√≠as:** Prefect ¬∑ Python ¬∑ Pandas ¬∑ MySQL ¬∑ Paramiko ¬∑ SQLAlchemy  

---

## üß© Resumen General

Este proyecto implementa un **pipeline ETL distribuido y tolerante a fallos** para procesar datos de visitas a un sitio web provenientes de archivos de texto.  
El flujo est√° **orquestado con Prefect**, empleando una **arquitectura Dispatcher/Performer** donde:

- El **Dispatcher** (flujo principal) identifica y distribuye archivos a procesar.  
- Los **Performers** (workers) ejecutan el ETL completo por archivo, en paralelo.  

Este dise√±o permite:
- Escalabilidad horizontal (a√±adir m√°s workers para procesar m√°s archivos).  
- Aislamiento de errores (un archivo fallido no detiene el flujo).  
- Monitoreo y trazabilidad granular por archivo procesado.  

---

## üèóÔ∏è Arquitectura de la Soluci√≥n

### Infraestructura

| Componente | Funci√≥n | Ubicaci√≥n |
|-------------|----------|-----------|
| **Servidor de Origen (SFTP)** | Almacena archivos fuente | `/home/vinkOS/archivosVisitas/` |
| **Servidor ETL** | Orquestador central y ejecuci√≥n ETL | `/home/etl/` |
| **Servidor de Destino (MySQL)** | Almacena resultados y bit√°coras | Tablas `visitantes`, `estadisticas`, `errores`, `bitacora_control` |

### Stack Tecnol√≥gico

- **Orquestaci√≥n:** Prefect (scheduler, retries, colas y monitoreo UI)
- **Procesamiento:** Python + Pandas
- **Conectividad:** Paramiko/pysftp
- **Carga:** SQLAlchemy (bulk insert/upsert)
- **Almacenamiento:** MySQL
- **Logging:** Logs detallados por tarea y archivo

### Ejecuci√≥n Distribuida (Micro-Batches)

Cada archivo es un **micro-batch independiente**.  
Los workers de Prefect procesan varios archivos en paralelo sin colisiones.  
Se limita la concurrencia de base de datos (ej. 8 conexiones simult√°neas).

---

## üóÉÔ∏è Esquema de Base de Datos

| Tabla | Prop√≥sito | Caracter√≠sticas |
|-------|------------|-----------------|
| **visitantes** | Registro consolidado por visitante (email) | Upsert mediante tabla staging temporal |
| **estadisticas** | Detalle de registros v√°lidos | Inserci√≥n por append |
| **errores** | Registros con fallos de validaci√≥n | Incluye tipo de error y fila original |
| **bitacora_control** | Trazabilidad de archivos procesados | M√©tricas y estatus de ejecuci√≥n |

---

## ‚öôÔ∏è Flujo del Proceso ETL

### 1Ô∏è‚É£ Dispatcher (Orquestador Principal)
- Se ejecuta diariamente (02:00 AM).  
- Lista archivos nuevos en el SFTP.  
- Filtra archivos ya procesados.  
- Encola un **work item** por archivo detectado.  
- Los workers escuchan la cola y procesan archivos en paralelo.

### 2Ô∏è‚É£ Performer (Flujo ETL por Archivo)

#### ETAPA 1: **Extract**
- Descarga el archivo del SFTP ‚Üí `/home/etl/staging/`
- Verifica integridad y tama√±o.
- Maneja reintentos autom√°ticos en fallos de red.

#### ETAPA 2: **Transform**
- Lee el archivo con Pandas (`pd.read_csv`)
- Valida layout (columnas esperadas).
- Valida emails, fechas y tipos de datos.
- Separa registros v√°lidos e inv√°lidos.
- Prepara tres DataFrames:
  - `df_estadisticas`
  - `df_errores`
  - `df_visitantes_staging` (agregaci√≥n por email)

#### ETAPA 3: **Load**
- Inicia transacci√≥n SQL (`BEGIN`)
- Inserta errores (`tabla errores`)
- Inserta estad√≠sticas (`tabla estadisticas`)
- Realiza **Upsert** en `visitantes` mediante tabla temporal y `ON DUPLICATE KEY UPDATE`
- Commit o rollback seg√∫n resultado.

#### ETAPA 4: **Post-Proceso**
- Registra resultado en `bitacora_control`
- Mueve archivo a `/home/etl/backup/`
- Elimina archivo del SFTP y limpia staging.

### 3Ô∏è‚É£ Cierre del Dispatcher
- Consolida backups ‚Üí `backup_YYYYMMDD.zip`
- Mueve archivos con fallos de sistema a cuarentena.
- Limpia staging.
- Genera reporte global del d√≠a (resumen de bit√°cora).

---

## üß± Estrategia de Resiliencia y Manejo de Errores

### üîß Errores de Sistema (t√©cnicos)
Ejemplos: fallos SFTP, MySQL, red o memoria.  
- **Nivel 1:** Reintentos autom√°ticos por tarea (3 intentos, delay exponencial).  
- **Nivel 2:** Reintentos de flujo completo.  
- **Nivel 3:** Si persiste ‚Üí se marca `FALLO_SISTEMA` y se mueve a cuarentena.  
- **Nivel 4:** Reintento autom√°tico al d√≠a siguiente (m√°x. 2 d√≠as).  

### ‚ö†Ô∏è Errores de Negocio - Validaciones
Ejemplos: emails inv√°lidos, fechas err√≥neas, nulos.  
- Se separan registros inv√°lidos sin detener el proceso.  
- Se insertan en `errores`.  
- Archivo marcado como `COMPLETADO_CON_ERRORES`.  

### ‚ùå Errores de Layout (fallos graves)
Ejemplos: columnas incorrectas o faltantes.  
- Se lanza excepci√≥n cr√≠tica.  
- Archivo marcado como `FALLO_LAYOUT`.  
- No se reintenta (requiere intervenci√≥n manual).  

---

## üìÇ Logs y Backups

**Logs**
- Ubicaci√≥n: `/home/etl/logs/YYYYMMDD/`
- Un archivo por proceso (`report_XXX.log`)
- Log del orquestador (`orchestrator_YYYYMMDD.log`)
- Retenci√≥n: 30 d√≠as (limpieza autom√°tica diaria)

**Backups**
- Carpeta: `/home/etl/backup/`
- Consolidado diario: `backup_YYYYMMDD.zip`
- Retenci√≥n: 90 d√≠as
- Incluye archivos exitosos, con errores y fallidos

---

## üß† Configuraci√≥n Prefect

### Flujos
| Flujo | Nombre | Tipo | Programaci√≥n |
|-------|---------|------|---------------|
| Dispatcher | `etl-visitas-web-dispatcher` | Principal | Diario 02:00 AM |
| Worker | `etl-visitas-web-worker` | Secundario | Activado por cola |



## üñ•Ô∏è Monitoreo Prefect UI

- **Dashboard en tiempo real** para visualizar ejecuciones activas.  
- **Hist√≥rico de ejecuciones filtrable** por fecha, estado y tags.  
- **Logs integrados y m√©tricas de performance** directamente en la UI.  
- **Alertas configurables** por email o webhook ante fallos o demoras.  

---

## üìä Monitoreo y Operaciones

### Dashboard (Grafana / Power BI / Tableau)
Basado en la tabla `bitacora_control`, incluye vistas como:

- Total de archivos procesados por d√≠a  
- Tasa de √©xito y archivos en cuarentena  
- Distribuci√≥n de estados (`COMPLETADO`, `CON_ERRORES`, `FALLO`)  
- Tasa de errores de datos y *top* tipos de error  

### Manual de Operaciones
Incluye escenarios de falla, diagn√≥stico y acciones recomendadas (SFTP, MySQL, red, etc.).  

---

## üßÆ Escalamiento a Big Data (Versi√≥n Spark)

Si el volumen de datos crece significativamente, la soluci√≥n puede migrarse a:

- **Apache Spark** como motor ETL (en lugar de Pandas)  
- **HDFS / Hive / Delta Lake** como destino  
- **Prefect** mantiene orquestaci√≥n mediante `spark-submit`  

### Adaptaciones Clave
- Procesamiento distribuido en cluster Hadoop o Kubernetes  
- Validaciones y agregaciones con operaciones de DataFrame de Spark  
- Carga en formato Parquet (append o merge mediante Delta Lake o Hudi)  

---

## üí° Notas Finales

El dise√±o fue asistido por **LLMs (Modelos de Lenguaje Grandes)**, que ayudaron en:

- Dise√±o conceptual del flujo y la arquitectura  
- Implementaci√≥n de *flows* y tareas en Prefect  
- Creaci√≥n del script SQL para el *upsert* de la tabla `visitantes`  

**Prefect** fue elegido sobre Airflow por su menor complejidad de configuraci√≥n y su f√°cil integraci√≥n con Python.  


